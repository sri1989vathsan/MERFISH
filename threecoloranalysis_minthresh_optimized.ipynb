{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os            # Operating system functionality\n",
    "import glob          # File system path manipulation\n",
    "import numpy as np   # Numerical operations\n",
    "#import nd2reader     # Not used in this script\n",
    "import napari        # Interactive multi-dimensional image viewer\n",
    "import bigfish       # Library for single-molecule fluorescence imaging\n",
    "import bigfish.stack as stack        # Functions for processing image stacks\n",
    "import bigfish.detection as detection  # Spot detection algorithms\n",
    "import bigfish.multistack as multistack  # Functions for multi-channel stacks\n",
    "import bigfish.plot as plot          # Plotting utilities\n",
    "import time          # Time tracking\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import tifffile as tiff  # Reading and writing TIFF files\n",
    "from skimage import io   # Image processing functions\n",
    "import plotly.express as px  # Expressive visualization library\n",
    "from nis2pyr.convertor import convert_nd2_to_pyramidal_ome_tiff\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_ROOT = \"./Test/\" ##Input Directory with the ND2 files\n",
    "DIR_TIFFFILES = os.path.join(DIR_ROOT,'TiffFiles') #New subdirectory where processed files will be saved\n",
    "DIR_MAXPROJ = os.path.join(DIR_TIFFFILES, 'Max_Projections')  # Directory for max projections\n",
    "DIR_REG = os.path.join(DIR_MAXPROJ, 'Registered')\n",
    "DIR_FOVS = os.path.join(DIR_MAXPROJ, 'FOVs')  # Directory for individual FOVs\n",
    "DIR_COMBINED_FILES = os.path.join(DIR_MAXPROJ, \"Combined_Files\") # a directory to save combined files if it doesn't exist\n",
    "DIR_SPOTS = os.path.join(DIR_MAXPROJ, 'Spots') #Save output spot files\n",
    "\n",
    "# Directories to check and create if they don't exist\n",
    "dirs_to_create = [DIR_TIFFFILES, DIR_MAXPROJ, DIR_FOVS, DIR_COMBINED_FILES, DIR_SPOTS, DIR_REG]\n",
    "\n",
    "# Loop through each directory\n",
    "for directory in dirs_to_create:\n",
    "    # Check if the directory does not exist\n",
    "    if not os.path.isdir(directory):\n",
    "        # If it doesn't, create the directory\n",
    "        os.mkdir(directory)\n",
    "\n",
    "# Define parameters\n",
    "voxelval = 110.3752759382\n",
    "##radiusval = 250.0\n",
    "radiusval = 2*voxelval\n",
    "NUM_CHANNELS=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Files as OME Tiffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All images are converte to .tif files and saved in the TiffFiles folder\n",
    "- Unclear yet how to change the LUTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Test/Round00_FOV0000.nd2\n",
      "Reading ./Test/Round00_FOV0000.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round00_FOV0000.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round00_FOV0001.nd2\n",
      "Reading ./Test/Round00_FOV0001.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round00_FOV0001.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round01_FOV0000.nd2\n",
      "Reading ./Test/Round01_FOV0000.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round01_FOV0000.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round01_FOV0001.nd2\n",
      "Reading ./Test/Round01_FOV0001.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round01_FOV0001.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round02_FOV0000.nd2\n",
      "Reading ./Test/Round02_FOV0000.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round02_FOV0000.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round02_FOV0001.nd2\n",
      "Reading ./Test/Round02_FOV0001.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round02_FOV0001.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round03_FOV0000.nd2\n",
      "Reading ./Test/Round03_FOV0000.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round03_FOV0000.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round03_FOV0001.nd2\n",
      "Reading ./Test/Round03_FOV0001.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round03_FOV0001.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round04_FOV0000.nd2\n",
      "Reading ./Test/Round04_FOV0000.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round04_FOV0000.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round04_FOV0001.nd2\n",
      "Reading ./Test/Round04_FOV0001.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round04_FOV0001.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round05_FOV0000.nd2\n",
      "Reading ./Test/Round05_FOV0000.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round05_FOV0000.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round05_FOV0001.nd2\n",
      "Reading ./Test/Round05_FOV0001.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round05_FOV0001.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round06_FOV0000.nd2\n",
      "Reading ./Test/Round06_FOV0000.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round06_FOV0000.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round06_FOV0001.nd2\n",
      "Reading ./Test/Round06_FOV0001.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round06_FOV0001.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round07_FOV0000.nd2\n",
      "Reading ./Test/Round07_FOV0000.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round07_FOV0000.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n",
      "./Test/Round07_FOV0001.nd2\n",
      "Reading ./Test/Round07_FOV0001.nd2\n",
      "ND2 dimensions: {'Z': 15, 'C': 4, 'Y': 2720, 'X': 2720}; RGB: False; datatype: uint16; legacy: False\n",
      "Saving pyramidal OME TIFF file ./Test/TiffFiles/Round07_FOV0001.tif\n",
      "Writing level 0: TZCYXS=(1, 15, 4, 2720, 2720, 1)\n",
      "Updating OME XML channel names and colors\n"
     ]
    }
   ],
   "source": [
    "# Filter ND2 files and remove those used for testing bleaching\n",
    "files = sorted([f for f in os.listdir(DIR_ROOT) if f.endswith('.nd2') and 'Bleach' not in f])\n",
    "\n",
    "# Iterate over each file in the 'files' list (all ND2 files)\n",
    "for fil in files:\n",
    "    # Print the directory and filename being processed\n",
    "    print(os.path.join(DIR_ROOT, fil))\n",
    "    \n",
    "    # Convert the ND2 file to pyramidal OME-TIFF format\n",
    "    # Specify the input ND2 file path, output OME-TIFF file path,\n",
    "    # and the maximum number of pyramid levels (set to 1 in this case)\n",
    "    convert_nd2_to_pyramidal_ome_tiff(os.path.join(DIR_ROOT, fil), \n",
    "                                    os.path.join(DIR_TIFFFILES, fil.split(\".\")[0] + '.tif'),\n",
    "                                    max_levels=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Intensity Projection and Image Distribution according to FOV \n",
    "So all images corresponding to the same FOV but across different cycles are saved in one folder \n",
    "- each image for one round is split by its channels and one channel image is saved\n",
    "- still need to figure out how to manage when there are multiple channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all TIFF files in the input directory and sort them\n",
    "files = sorted([f for f in os.listdir(DIR_TIFFFILES) if f.endswith('.tif')])\n",
    "\n",
    "# Define a function to compute maximum intensity projection along the Z-axis\n",
    "def maximum_intensity_projection(image_stack):\n",
    "    return np.max(image_stack, axis=0)\n",
    "\n",
    "# Loop through each TIFF file\n",
    "for fil in files:\n",
    "    # Read the OME-TIFF file\n",
    "    ome_tiff_path = os.path.join(DIR_TIFFFILES, fil)\n",
    "    image_stack = tiff.imread(ome_tiff_path)\n",
    "    \n",
    "    # Compute the maximum intensity projection\n",
    "    mip = maximum_intensity_projection(image_stack)\n",
    "    \n",
    "    # Save the max projection image\n",
    "    mip_path = os.path.join(DIR_MAXPROJ, \"MAX_\" + os.path.splitext(fil)[0] + \".tif\")\n",
    "    tiff.imsave(mip_path, mip)\n",
    "    \n",
    "    # Extract FOV information from the filename\n",
    "    FOV = os.path.splitext(fil)[0].split(\"_\")\n",
    "    \n",
    "    # Create a directory for the FOV if it does not exist\n",
    "    dir5 = os.path.join(DIR_FOVS, FOV[1])\n",
    "    os.makedirs(dir5, exist_ok=True)\n",
    "    \n",
    "    # Save each channel of the max projection image as a separate TIFF file\n",
    "    for chan, channel_image in enumerate(mip, start=1):\n",
    "        savename = os.path.join(dir5, f\"{FOV[0]}_channel_{chan}.tif\")\n",
    "        tiff.imsave(savename, channel_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Files combining images from single channel and single FOV across all cycles\n",
    "- This helps in easy visualization of the data and can also be used for data analysis? \n",
    "- the files are saved in the Max_Projection/Combined_Files/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of directories in DIR_MAXPROJ\n",
    "directories = [name for name in os.listdir(DIR_FOVS) if os.path.isdir(os.path.join(DIR_FOVS, name))]\n",
    "directories.sort()  # Sort the list of directories\n",
    "\n",
    "# Iterate over each directory\n",
    "for directory in directories:\n",
    "    # Create full path to the current directory\n",
    "    dir_path = os.path.join(DIR_FOVS, directory)\n",
    "    \n",
    "    # Get list of TIFF files in the directory and sort them\n",
    "    tiff_files = sorted([f for f in os.listdir(dir_path) if f.endswith('.tif')])\n",
    "    sample_image = os.path.join(dir_path,tiff_files[0])\n",
    "    channel_image = tiff.imread(sample_image)\n",
    "    \n",
    "    # Extract channel information from TIFF filenames\n",
    "    channels = [f.split('_')[2] for f in tiff_files]\n",
    "    unique_channels = np.unique(channels)\n",
    "    \n",
    "    # Iterate over each unique channel\n",
    "    for channel in unique_channels:\n",
    "        # Get indices of TIFF files corresponding to the current channel\n",
    "        indices = [i for i, c in enumerate(channels) if c == channel]\n",
    "        \n",
    "        # Initialize array for multichannel image\n",
    "        multichannel_image = np.zeros((len(indices), channel_image.shape[0], channel_image.shape[1]))\n",
    "        \n",
    "        # Iterate over each TIFF file corresponding to the current channel\n",
    "        for i, index in enumerate(indices):\n",
    "            # Read TIFF file\n",
    "            img = tiff.imread(os.path.join(dir_path, tiff_files[index]))\n",
    "            # Store image in multichannel array\n",
    "            multichannel_image[i, :, :] = img\n",
    "        \n",
    "        # Define filename for combined multichannel image\n",
    "        savename = os.path.join(DIR_COMBINED_FILES, f\"{directory}_channel_{channel}\")\n",
    "        # Save combined multichannel image as TIFF\n",
    "        tiff.imsave(savename, multichannel_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Test/TiffFiles/Max_Projections/Combined_Files/FOV0000_channel_4.tif\n",
      "Number of images in the stack: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:45<00:00,  7.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Test/TiffFiles/Max_Projections/Combined_Files/FOV0000_channel_1.tif\n",
      "./Test/TiffFiles/Max_Projections/Combined_Files/FOV0000_channel_2.tif\n",
      "./Test/TiffFiles/Max_Projections/Combined_Files/FOV0000_channel_3.tif\n",
      "./Test/TiffFiles/Max_Projections/Combined_Files/FOV0000_channel_4.tif\n",
      "./Test/TiffFiles/Max_Projections/Combined_Files/FOV0001_channel_4.tif\n",
      "Number of images in the stack: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:48<00:00,  8.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Test/TiffFiles/Max_Projections/Combined_Files/FOV0001_channel_1.tif\n",
      "./Test/TiffFiles/Max_Projections/Combined_Files/FOV0001_channel_2.tif\n",
      "./Test/TiffFiles/Max_Projections/Combined_Files/FOV0001_channel_3.tif\n",
      "./Test/TiffFiles/Max_Projections/Combined_Files/FOV0001_channel_4.tif\n"
     ]
    }
   ],
   "source": [
    "from pystackreg import StackReg\n",
    "from skimage import transform, io, exposure\n",
    "\n",
    "files = sorted([each for each in os.listdir(DIR_COMBINED_FILES) if each.endswith('.tif')])\n",
    "\n",
    "for x in range(int(len(files)/NUM_CHANNELS)):\n",
    "    filename = os.path.join(DIR_COMBINED_FILES,files[x*4+(NUM_CHANNELS-1)])\n",
    "    unreg = tiff.imread(filename)[1:,:,:]\n",
    "    print(filename)\n",
    "    print(f\"Number of images in the stack: {len(unreg)}\")\n",
    "    reference = 'previous'\n",
    "    sr = StackReg(StackReg.RIGID_BODY)\n",
    "    tmat = sr.register_stack(unreg, axis=0, reference=reference, verbose=True)\n",
    "    for y in range(NUM_CHANNELS):\n",
    "        filename = os.path.join(DIR_COMBINED_FILES,files[x*NUM_CHANNELS+y])\n",
    "        print(filename)\n",
    "        unreg = tiff.imread(filename)[1:,:,:]\n",
    "        reg = sr.transform_stack(unreg)\n",
    "        savename = os.path.join(DIR_REG,files[x*NUM_CHANNELS+y])\n",
    "        tiff.imsave(savename, reg)\n",
    "\n",
    "print(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FISH Spot Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detecting threshold within multiple FOVs for all rounds and channels\n",
    "- This could potentially be used to get a global threshold value\n",
    "- Alternatively can be used to get individual thresholds for each channel and round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start 0.37445783615112305 seconds ---\n",
      "FOV0000_channel_1.tif\n",
      "--- Start 14.767953872680664 seconds ---\n",
      "FOV0001_channel_1.tif\n",
      "Finished thresholding for channel 1 after 35.15138387680054 seconds ---\n",
      "--- Start 35.15148878097534 seconds ---\n",
      "FOV0000_channel_2.tif\n",
      "--- Start 50.53353691101074 seconds ---\n",
      "FOV0001_channel_2.tif\n",
      "Finished thresholding for channel 2 after 70.08184885978699 seconds ---\n",
      "--- Start 70.08220386505127 seconds ---\n",
      "FOV0000_channel_3.tif\n",
      "--- Start 82.17321681976318 seconds ---\n",
      "FOV0001_channel_3.tif\n",
      "Finished thresholding for channel 3 after 96.40208601951599 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Threshold values for each channel\n",
    "thresholds = [18, 18, 18]  # Thresholds for Channels 1, 2, and 3\n",
    "\n",
    "# Number of cycles for each channel\n",
    "channel_rounds = [8, 8, 8]\n",
    "\n",
    "# Number of FOVs to use to detect thresholds\n",
    "NFOVS = 2\n",
    "\n",
    "directories = [name for name in os.listdir(DIR_FOVS) if os.path.isdir(os.path.join(DIR_FOVS, name))]\n",
    "dir_path = os.path.join(DIR_FOVS, directories[0])\n",
    "\n",
    "# Get list of TIFF files in the directory and sort them\n",
    "tiff_files = sorted([f for f in os.listdir(dir_path) if f.endswith('.tif')])\n",
    "sample_image = os.path.join(dir_path,tiff_files[0])\n",
    "channel_image = tiff.imread(sample_image)\n",
    "\n",
    "# Extract channel information from TIFF filenames\n",
    "channels = [f.split('_')[2] for f in tiff_files]\n",
    "unique_channels = np.unique(channels)\n",
    "\n",
    "# Get list of TIFF files in the combined files directory and sort them\n",
    "#files = sorted([f for f in os.listdir(DIR_COMBINED_FILES) if f.endswith('.tif')])\n",
    "files = sorted([f for f in os.listdir(DIR_REG) if f.endswith('.tif')])\n",
    "\n",
    "# Compute spot radius in pixels\n",
    "spot_radius_px = detection.get_object_radius_pixel(\n",
    "                    voxel_size_nm=(voxelval, voxelval), \n",
    "                    object_radius_nm=(radiusval, radiusval), \n",
    "                    ndim=2)\n",
    "\n",
    "ths1 = np.zeros((channel_rounds[0]*NFOVS, 1))\n",
    "ths2 = np.zeros((channel_rounds[1]*NFOVS, 1))\n",
    "ths3 = np.zeros((channel_rounds[2]*NFOVS, 1))\n",
    "\n",
    "# Iterate over each channel\n",
    "for channel, threshold, rounds in zip(range(3), thresholds, channel_rounds):\n",
    "    e = 0\n",
    "    for fil in range(NFOVS):\n",
    "        print(f\"--- Start {time.time() - start_time} seconds ---\")\n",
    "        filename = files[fil * len(unique_channels) + channel]\n",
    "        #img = tiff.imread(os.path.join(DIR_COMBINED_FILES, filename))\n",
    "        img = tiff.imread(os.path.join(DIR_REG, filename))\n",
    "        print(filename)\n",
    "        # Detect spots\n",
    "        for t in range(img.shape[0]):\n",
    "            rna = img[t, :, :]\n",
    "            # LoG filter\n",
    "            rna_log = stack.log_filter(rna, sigma=spot_radius_px)\n",
    "            # Local maximum detection\n",
    "            mask = detection.local_maximum_detection(rna_log, min_distance=spot_radius_px)\n",
    "            # Thresholding\n",
    "            threshold_value = detection.automated_threshold_setting(rna_log, mask)\n",
    "            if channel == 0:\n",
    "                ths1[e] = threshold_value\n",
    "            elif channel == 1:\n",
    "                ths2[e] = threshold_value\n",
    "            else:\n",
    "                ths3[e] = threshold_value\n",
    "            e += 1\n",
    "    print(f\"Finished thresholding for channel {channel + 1} after {time.time() - start_time} seconds ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying threshold to detect spots and clusters\n",
    "- spots are saved in the Spots folder as FOV##\\_Channel##\\_#.csv\n",
    "- spot clusters are save in the Spots folder as FOV##\\_Channel##\\_spotclusters_#.csv\n",
    "- clusters information is save in the Spots folder as FOV##\\_Channel##\\_clusters\\_#.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start 0.10430312156677246 seconds ---\n",
      "0\n",
      "Analysing Channel 0\n",
      "FOV0000_channel_1.tif\n",
      "Analysing Round 1\n",
      "Analysing Round 2\n",
      "Analysing Round 3\n",
      "Analysing Round 4\n",
      "Analysing Round 5\n",
      "Analysing Round 6\n",
      "Analysing Channel 1\n",
      "FOV0000_channel_2.tif\n",
      "Analysing Round 1\n",
      "Analysing Round 2\n",
      "Analysing Round 3\n",
      "Analysing Round 4\n",
      "Analysing Round 5\n",
      "Analysing Round 6\n",
      "Analysing Channel 2\n",
      "FOV0000_channel_3.tif\n",
      "Analysing Round 1\n",
      "Analysing Round 2\n",
      "Analysing Round 3\n",
      "Analysing Round 4\n",
      "Analysing Round 5\n",
      "Analysing Round 6\n",
      "--- Start 120.26968121528625 seconds ---\n",
      "1\n",
      "Analysing Channel 0\n",
      "FOV0001_channel_1.tif\n",
      "Analysing Round 1\n",
      "Analysing Round 2\n",
      "Analysing Round 3\n",
      "Analysing Round 4\n",
      "Analysing Round 5\n",
      "Analysing Round 6\n",
      "Analysing Channel 1\n",
      "FOV0001_channel_2.tif\n",
      "Analysing Round 1\n",
      "Analysing Round 2\n",
      "Analysing Round 3\n",
      "Analysing Round 4\n",
      "Analysing Round 5\n",
      "Analysing Round 6\n",
      "Analysing Channel 2\n",
      "FOV0001_channel_3.tif\n",
      "Analysing Round 1\n",
      "Analysing Round 2\n",
      "Analysing Round 3\n",
      "Analysing Round 4\n",
      "Analysing Round 5\n",
      "Analysing Round 6\n",
      "Finished thresholding for channel 1 image 14 after 247.13528609275818 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Compute thresholds\n",
    "thresholds = [np.median(ths) for ths in [ths1, ths2, ths3]]\n",
    "\n",
    "# Get list of TIFF files\n",
    "#files = sorted([each for each in os.listdir(DIR_COMBINED_FILES) if each.endswith('.tif')])\n",
    "files = sorted([each for each in os.listdir(DIR_REG) if each.endswith('.tif')])\n",
    "NFOVS = len(files) // len(unique_channels)\n",
    "\n",
    "\n",
    "for fil in range(NFOVS):\n",
    "    print(\"--- Start %s seconds ---\" % (time.time() - start_time))\n",
    "    print(fil)\n",
    "    for cc, channel in enumerate(unique_channels[0:-1]):\n",
    "        print(\"Analysing Channel %s\" % cc)\n",
    "        filename = files[fil * len(unique_channels) + cc]\n",
    "        print(filename)\n",
    "        #img = tiff.imread(os.path.join(DIR_COMBINED_FILES, filename))\n",
    "        img = tiff.imread(os.path.join(DIR_REG, filename))\n",
    "        #savedir = os.path.join(DIR_FOVS, \"Combined_Files\")\n",
    "        savenamespots = filename.split(\".\")[0] + \".csv\"\n",
    "        savenamespotscl = filename.split(\".\")[0] + \"_spotclusters.csv\"\n",
    "        savenameclusters = filename.split(\".\")[0] + \"_clusters.csv\"\n",
    "\n",
    "        sp = pd.DataFrame()\n",
    "        spcl = pd.DataFrame()\n",
    "        cl = pd.DataFrame()\n",
    "\n",
    "        # Detect spots\n",
    "        for t in range(img.shape[0] - 1):\n",
    "            print(\"Analysing Round %s\" % (t + 1))\n",
    "            rna = img[t + 1, :, :]\n",
    "            rna_log = stack.log_filter(rna, sigma=spot_radius_px)\n",
    "            # Local maximum detection\n",
    "            mask = detection.local_maximum_detection(rna_log, min_distance=spot_radius_px)\n",
    "            # Thresholding\n",
    "            threshold_value = detection.automated_threshold_setting(rna_log, mask)\n",
    "            # LoG filter\n",
    "            if threshold_value < thresholds[cc]:\n",
    "                CURR_THRESHOLD=thresholds[cc]\n",
    "            else:\n",
    "                CURR_THRESHOLD=threshold_value\n",
    "            \n",
    "            spots = detection.detect_spots(\n",
    "                images=rna,\n",
    "                return_threshold=False,\n",
    "                threshold=CURR_THRESHOLD,\n",
    "                voxel_size=(voxelval, voxelval),  # in nanometer (one value per dimension zyx)\n",
    "                spot_radius=(radiusval, radiusval)  # in nanometer (one value per dimension zyx)\n",
    "            )\n",
    "\n",
    "            spots_post_decomposition, dense_regions, reference_spot = detection.decompose_dense(\n",
    "                image=np.uint16(rna),\n",
    "                spots=spots,\n",
    "                voxel_size=(voxelval, voxelval),\n",
    "                spot_radius=(radiusval, radiusval),\n",
    "                alpha=0.75,  # alpha impacts the number of spots per candidate region\n",
    "                beta=0.9,  # beta impacts the number of candidate regions to decompose\n",
    "                gamma=15  # gamma the filtering step to denoise the image\n",
    "            )\n",
    "\n",
    "            spots_post_clustering, clusters = detection.detect_clusters(\n",
    "                spots=spots_post_decomposition,\n",
    "                voxel_size=(int(voxelval), int(voxelval)),\n",
    "                radius=int(radiusval),\n",
    "                nb_min_spots=4\n",
    "            )\n",
    "\n",
    "            spotspd = pd.DataFrame(spots)\n",
    "            spclpd = pd.DataFrame(spots_post_clustering)\n",
    "            clupd = pd.DataFrame(clusters)\n",
    "\n",
    "            spotspd['round'] = t\n",
    "            spclpd['round'] = t\n",
    "            clupd['round'] = t\n",
    "\n",
    "            sp = pd.concat([sp, spotspd])\n",
    "            spcl = pd.concat([spcl, spclpd])\n",
    "            cl = pd.concat([cl, clupd])\n",
    "\n",
    "        sp.columns = ['Y', 'X', 'round']\n",
    "        cl.columns = ['Y', 'X', 'nspots', 'index', 'round']\n",
    "        spcl.columns = ['Y', 'X', 'clusterindex', 'round']\n",
    "\n",
    "        sp.to_csv(os.path.join(DIR_SPOTS, savenamespots), index=False)\n",
    "        spcl.to_csv(os.path.join(DIR_SPOTS, savenamespotscl), index=False)\n",
    "        cl.to_csv(os.path.join(DIR_SPOTS, savenameclusters), index=False)\n",
    "\n",
    "print(\"Finished thresholding for channel 1 image %s after %s seconds ---\" % (e, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Napari Viewer to visualize overlay of spots on FISH images\n",
    "- checking signal quality\n",
    "- see if threshold needs to be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asrivath/opt/anaconda3/envs/fish/lib/python3.7/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/asrivath/opt/anaconda3/envs/fish/lib/python3.7/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/asrivath/opt/anaconda3/envs/fish/lib/python3.7/site-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAUSE BREAK\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "# Initialize Napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Define parameters\n",
    "#files = sorted([f for f in os.listdir(DIR_COMBINED_FILES) if f.endswith('.tif')])\n",
    "#img = tiff.imread(os.path.join(DIR_COMBINED_FILES, files[0]))\n",
    "files = sorted([f for f in os.listdir(DIR_REG) if f.endswith('.tif')])\n",
    "img = tiff.imread(os.path.join(DIR_REG, files[0]))\n",
    "GAP_SIZE = img.shape[1]+10\n",
    "CHANNELS = pd.unique(pd.DataFrame(np.stack(np.char.split(files, sep=\"_\"), axis=0))[2])\n",
    "NFOVS = len(files) // len(CHANNELS)\n",
    "\n",
    "GENES_CY7 = ['Dpp10', 'Dpp8', 'Dst', 'Fat1', 'Itgb4', 'Larp1', 'Larp7']\n",
    "GENES_CY5 = ['Apob', 'Cdh1', 'Ctnnb1', 'Cyb5r3', 'mTor', 'Net1', 'Pigr']\n",
    "GENES_CY3 = ['Dync1h1', 'Dync1i2', 'Eif4h', 'Kif1c', 'Kif3b', 'Kif5b', 'None']\n",
    "color = px.colors.qualitative.Light24\n",
    "\n",
    "# Initialize variables\n",
    "SPOTS_CY7 = pd.DataFrame()\n",
    "SPOTS_CY5 = pd.DataFrame()\n",
    "SPOTS_CY3 = pd.DataFrame()\n",
    "#TOTAL_AREA = nearest_square(len(files) *(len(GENES_CY3)+len(GENES_CY5)+len(GENES_CY7))/4)\n",
    "NUM_ROUNDS = len(GENES_CY7)+1\n",
    "NUM_CHANNELS = len(CHANNELS)-1\n",
    "TOTAL_AREA = NFOVS*NUM_CHANNELS\n",
    "image = np.zeros((GAP_SIZE * NUM_ROUNDS, GAP_SIZE * TOTAL_AREA), dtype=np.int16)\n",
    "xx = 0\n",
    "yy = 0\n",
    "polygons =[]\n",
    "text = np.array([], dtype=np.unicode_).reshape(0,1)\n",
    "\n",
    "for fov in range(NFOVS):\n",
    "    for cc, genes in enumerate([GENES_CY7, GENES_CY5, GENES_CY3]):\n",
    "        image_name = os.path.join(DIR_COMBINED_FILES,files[len(CHANNELS) * fov + cc])\n",
    "        im2 = tiff.imread(image_name)\n",
    "        file_name = files[fov * len(CHANNELS) + cc]\n",
    "        spot = pd.read_csv(os.path.join(DIR_SPOTS, file_name.split(\".\")[0] + \"_spotclusters.csv\"))\n",
    "        for ch_count in range(0,len(genes)+1):\n",
    "            image[xx * GAP_SIZE:xx * GAP_SIZE + im2.shape[1], yy * GAP_SIZE:yy * GAP_SIZE + im2.shape[1]] = im2[ch_count, :, :]\n",
    "            spots = spot[spot['round'] == ch_count] \n",
    "            spots['Y'] += (xx+1) * GAP_SIZE\n",
    "            spots['X'] += (yy) * GAP_SIZE\n",
    "            spots['gene'] = spots['round'].apply(lambda x: genes[x]).values\n",
    "            if cc == 0:\n",
    "                SPOTS_CY7 = pd.concat([SPOTS_CY7, spots])\n",
    "            elif cc == 1:\n",
    "                SPOTS_CY5 = pd.concat([SPOTS_CY5, spots])\n",
    "            elif cc == 2:\n",
    "                SPOTS_CY3 = pd.concat([SPOTS_CY3, spots])\n",
    "            \n",
    "            polygons.append(np.array([[xx*GAP_SIZE, yy*GAP_SIZE], [xx*GAP_SIZE+im2.shape[1], yy*GAP_SIZE], [xx*GAP_SIZE+im2.shape[1], yy*GAP_SIZE+im2.shape[1]], [xx*GAP_SIZE, yy*GAP_SIZE+im2.shape[1]]]))\n",
    "            text = np.vstack([text,image_name.split('/')[-1].split('.')[0]])\n",
    "            xx += 1\n",
    "            if xx > NUM_ROUNDS - 1:\n",
    "                xx = 0\n",
    "                yy += 1\n",
    "                \n",
    "print(\"PAUSE BREAK\")\n",
    "# Add image to viewer\n",
    "image_layers = [np.uint16(image[::2 ** i, ::2 ** i]) for i in range(int(np.log2(GAP_SIZE)) + 1)]\n",
    "image_layer = viewer.add_image(image_layers)\n",
    "image_layer.contrast_limits = (0, 65000)\n",
    "\n",
    "# create properties\n",
    "properties = {\n",
    "    #'likelihood': [21.23423, 51.2315, 100],\n",
    "    'class': text.flatten().tolist(),\n",
    "}\n",
    "edge_color_cycle = ['black']\n",
    "\n",
    "text_properties = {\n",
    "    'text': '{class}',\n",
    "    'anchor': 'upper_left',\n",
    "    'translation': [-5, 0],\n",
    "    'size': 15,\n",
    "    'color': 'white',\n",
    "}\n",
    "# add polygons\n",
    "shapes_layer = viewer.add_shapes(\n",
    "    polygons,\n",
    "    properties=properties,\n",
    "    shape_type='polygon',\n",
    "    edge_width=1,\n",
    "    #edge_color='class',\n",
    "    #edge_color_cycle=edge_color_cycle,\n",
    "    face_color='transparent',\n",
    "    text=text_properties,\n",
    "    #name='shapes',\n",
    ")\n",
    "\n",
    "# change some properties of the layer\n",
    "shapes_layer.opacity = 1\n",
    "\n",
    "print(\"PAUSE\")\n",
    "count=0\n",
    "# Add spots to viewer\n",
    "all_spots = pd.concat([SPOTS_CY7, SPOTS_CY5, SPOTS_CY3])\n",
    "#for fov in range(NFOVS):\n",
    "for genes in [GENES_CY7, GENES_CY5, GENES_CY3]:\n",
    "    for round in genes:\n",
    "        cy = np.array(all_spots[all_spots['gene'] == round])[:,:2]\n",
    "        viewer.add_points(cy,\n",
    "                        #spots[::2,::2],\n",
    "                        #spots[::4,::4]],\n",
    "                        face_color=color[count],\n",
    "                        size=5, blending='translucent_no_depth', edge_width=0, name=round)\n",
    "        count = count+1\n",
    "        if count>len(color)-1:\n",
    "            count=0\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Napari viewer\n",
    "- View all images in one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOV0000_channel_4.tif\n",
      "FOV0001_channel_4.tif\n"
     ]
    }
   ],
   "source": [
    "def nearest_square(limit):\n",
    "    return int(math.ceil(limit ** 0.5))\n",
    "\n",
    "# Initialize Napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Define parameters\n",
    "#files = sorted([f for f in os.listdir(DIR_COMBINED_FILES) if f.endswith('.tif')])\n",
    "#img = tiff.imread(os.path.join(DIR_COMBINED_FILES, files[0]))\n",
    "files = sorted([f for f in os.listdir(DIR_REG) if f.endswith('.tif')])\n",
    "img = tiff.imread(os.path.join(DIR_REG, files[0]))\n",
    "GAP_SIZE = img.shape[1]+50\n",
    "CHANNELS = pd.unique(pd.DataFrame(np.stack(np.char.split(files, sep=\"_\"), axis=0))[2])\n",
    "NFOVS = len(files) // len(CHANNELS)\n",
    "\n",
    "GENES_CY7 = ['Dpp10', 'Dpp8', 'Dst', 'Fat1', 'Itgb4', 'Larp1', 'Larp7']\n",
    "GENES_CY5 = ['Apob', 'Cdh1', 'Ctnnb1', 'Cyb5r3', 'mTor', 'Net1', 'Pigr']\n",
    "GENES_CY3 = ['Dync1h1', 'Dync1i2', 'Eif4h', 'Kif1c', 'Kif3b', 'Kif5b', 'None']\n",
    "color = px.colors.qualitative.Light24\n",
    "\n",
    "# Initialize variables\n",
    "SPOTS_CY7 = pd.DataFrame()\n",
    "SPOTS_CY5 = pd.DataFrame()\n",
    "SPOTS_CY3 = pd.DataFrame()\n",
    "TOTAL_AREA = nearest_square(len(files) / 4)\n",
    "image = np.zeros((GAP_SIZE * TOTAL_AREA, GAP_SIZE * TOTAL_AREA), dtype=np.int16)\n",
    "xx = 0\n",
    "yy = 0\n",
    "polygons =[]\n",
    "text = np.array([], dtype=np.unicode_).reshape(0,1)\n",
    "\n",
    "for fov in range(NFOVS):\n",
    "    image_name = files[len(CHANNELS) * fov + 3]\n",
    "    print(image_name)\n",
    "    #image_loc = os.path.join(DIR_COMBINED_FILES, image_name)\n",
    "    image_loc = os.path.join(DIR_REG, image_name)\n",
    "    im2 = tiff.imread(image_loc)\n",
    "    image[xx * GAP_SIZE:xx * GAP_SIZE + im2.shape[1], yy * GAP_SIZE:yy * GAP_SIZE + im2.shape[1]] = im2[0, :, :]\n",
    "\n",
    "    for cc, genes in enumerate([GENES_CY7, GENES_CY5, GENES_CY3]):\n",
    "        file_name = files[fov * len(CHANNELS) + cc]\n",
    "        spots = pd.read_csv(os.path.join(DIR_SPOTS, file_name.split(\".\")[0] + \"_spotclusters.csv\"))\n",
    "        spots['Y'] += xx * GAP_SIZE\n",
    "        spots['X'] += yy * GAP_SIZE\n",
    "        spots['gene'] = spots['round'].apply(lambda x: genes[x]).values\n",
    "        if cc == 0:\n",
    "            SPOTS_CY7 = pd.concat([SPOTS_CY7, spots])\n",
    "        elif cc == 1:\n",
    "            SPOTS_CY5 = pd.concat([SPOTS_CY5, spots])\n",
    "        elif cc == 2:\n",
    "            SPOTS_CY3 = pd.concat([SPOTS_CY3, spots])\n",
    "        \n",
    "    polygons.append(np.array([[xx*GAP_SIZE, yy*GAP_SIZE], [xx*GAP_SIZE+im2.shape[1], yy*GAP_SIZE], [xx*GAP_SIZE+im2.shape[1], yy*GAP_SIZE+im2.shape[1]], [xx*GAP_SIZE, yy*GAP_SIZE+im2.shape[1]]]))\n",
    "    text = np.vstack([text,image_name.split('_')[0]])\n",
    "    \n",
    "        \n",
    "    xx += 1\n",
    "    if xx > TOTAL_AREA - 1:\n",
    "        xx = 0\n",
    "        yy += 1\n",
    "\n",
    "# Add image to viewer\n",
    "image_layers = [np.uint16(image[::2 ** i, ::2 ** i]) for i in range(int(np.log2(GAP_SIZE)) + 1)]\n",
    "image_layer = viewer.add_image(image_layers)\n",
    "image_layer.contrast_limits = (0, 65000)\n",
    "\n",
    "# create properties\n",
    "properties = {\n",
    "    #'likelihood': [21.23423, 51.2315, 100],\n",
    "    'class': text.flatten().tolist(),\n",
    "}\n",
    "edge_color_cycle = ['black']\n",
    "\n",
    "text_properties = {\n",
    "    'text': '{class}',\n",
    "    'anchor': 'upper_left',\n",
    "    'translation': [-5, 0],\n",
    "    'size': 15,\n",
    "    'color': 'white',\n",
    "}\n",
    "# add polygons\n",
    "shapes_layer = viewer.add_shapes(\n",
    "    polygons,\n",
    "    properties=properties,\n",
    "    shape_type='polygon',\n",
    "    edge_width=1,\n",
    "    #edge_color='class',\n",
    "    #edge_color_cycle=edge_color_cycle,\n",
    "    face_color='transparent',\n",
    "    text=text_properties,\n",
    "    #name='shapes',\n",
    ")\n",
    "\n",
    "# change some properties of the layer\n",
    "shapes_layer.opacity = 1\n",
    "\n",
    "# Concatenate all spots\n",
    "all_spots = pd.concat([SPOTS_CY7, SPOTS_CY5, SPOTS_CY3])\n",
    "count=0\n",
    "# Add spots to viewer\n",
    "for genes in [GENES_CY7, GENES_CY5, GENES_CY3]:\n",
    "    for round in genes:\n",
    "        cy = all_spots[all_spots['gene'] == round]\n",
    "        spots = np.array(cy)[:, :2]\n",
    "        viewer.add_points(spots,\n",
    "                          #spots[::2,::2],\n",
    "                          #spots[::4,::4]],\n",
    "                          face_color=color[count],\n",
    "                          size=5, blending='translucent_no_depth', edge_width=0, name=round)\n",
    "        count = count+1\n",
    "        if count>len(color):\n",
    "            count=0\n",
    "            \n",
    "# Export features and all spots\n",
    "all_spots['gene'].to_csv(os.path.join(DIR_SPOTS, 'features.csv'), index=False)\n",
    "all_spots.to_csv(os.path.join(DIR_SPOTS, \"allspots.csv\"), index=False)\n",
    "\n",
    "feat = tuple(np.array(all_spots['gene']))\n",
    "point_layer = viewer.add_points(np.array(all_spots)[:, :2], face_color='white', size=5,\n",
    "                                 blending='translucent_no_depth', edge_width=0, name='All_spots', opacity=0,\n",
    "                                 features=feat)\n",
    "\n",
    "point_layer.refresh()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('multifish')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd4506f47e7a8e319038edbecbacc3135e1dea1a0fd1c74135d4055cf5626a52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
